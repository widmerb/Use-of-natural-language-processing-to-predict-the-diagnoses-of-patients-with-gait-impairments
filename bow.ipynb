{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9691e5-c20f-428d-aa36-1063700e3c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from Levenshtein import distance\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bece81-6220-46d3-b2e3-6e042b0d0d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "workingDir = os.path.abspath(os.path.join(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72abee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global var\n",
    "language = 'german'\n",
    "\n",
    "ngram_range = (1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0486da28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define scroing metrics\n",
    "scoring = [\"accuracy\", \"precision_micro\", \"recall_micro\", \"f1_micro\", \"precision_macro\", \"recall_macro\", \"f1_macro\"]\n",
    "refit = 'f1_macro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3944702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell_correction(word, corpus):\n",
    "    # Check if the word is not in the corpus\n",
    "    if word not in corpus:\n",
    "        # Calculate the Levenshtein distance between the word and each word in the corpus\n",
    "        distances = [distance(word, c) for c in corpus]\n",
    "        # Find the index of the minimum distance\n",
    "        min_index = distances.index(min(distances))\n",
    "        # If the minimum distance is less than or equal to the length of the word divided by 10 plus 1,\n",
    "        # replace the word with the closest word from the corpus\n",
    "        if len(word) / 10 + 1 >= min(distances):\n",
    "            word = corpus[min_index]\n",
    "    return word"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dea99196",
   "metadata": {},
   "source": [
    "### read df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7427ba-0458-4398-91c1-d0d7c310f48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(filepath_or_buffer=os.path.join(workingDir, 'data', 'train.csv'))\n",
    "df_test = pd.read_csv(filepath_or_buffer=os.path.join(workingDir, 'data', 'test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9c5f40",
   "metadata": {},
   "source": [
    "correct test set vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1183fe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = [word for sentence in df_train[f\"input_{language}\"] for word in sentence.split()]\n",
    "# Create a corpus as a set of unique words\n",
    "corpus = list(set(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ce08a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "# Iterate over each sentence in the test dataframe\n",
    "for sen in range(0, len(df_test[f\"input_{language}\"])):\n",
    "    # Convert the sentence to a string\n",
    "    document = str(df_test[f\"input_{language}\"][sen])\n",
    "    # Split the sentence into words\n",
    "    document = document.split()\n",
    "    # Apply spell correction to each word in the sentence\n",
    "    document = [spell_correction(word, corpus) for word in document]\n",
    "    # Join the corrected words back into a single string\n",
    "    document = ' '.join(document)\n",
    "    \n",
    "    # Append the corrected sentence to the documents list\n",
    "    documents.append(document)\n",
    "\n",
    "df_test[f\"input_{language}\"] = pd.DataFrame({f\"input_{language}\": documents})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e919cc-c282-4ffc-b848-7491f9756720",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train[f\"input_{language}\"], df_train.Topology\n",
    "X_test, y_test = df_test[f\"input_{language}\"], df_test.Topology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84071627",
   "metadata": {},
   "source": [
    "# Prepare the data\n",
    "## transform text to set of words representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862b788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_var(X_train, X_test, ngram_range):\n",
    "    # Initialize the CountVectorizer with specified parameters\n",
    "    vectorizer = CountVectorizer(max_features=500, \n",
    "                                 min_df=2, \n",
    "                                 max_df=0.8,\n",
    "                                 ngram_range=ngram_range,                          \n",
    "                                 stop_words=stopwords.words(language))\n",
    "    \n",
    "    # Fit the vectorizer on the training data and transform the training data into a document-term matrix\n",
    "    X_train_vec = vectorizer.fit_transform(X_train).toarray()\n",
    "    \n",
    "    # Transform the test data into a document-term matrix using the fitted vectorizer\n",
    "    X_test_vec = vectorizer.transform(X_test).toarray()\n",
    "    \n",
    "    return X_train_vec, X_test_vec\n",
    "\n",
    "# Convert the text data into numerical vectors using the defined function\n",
    "X_train_vec, X_test_vec = text_to_var(X_train, X_test, ngram_range)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9694228-53d5-45a4-8e4d-cd0e5ff39369",
   "metadata": {},
   "source": [
    "## text to predict Topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927bf977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results_topology(y_test, y_pred):\n",
    "        # Get the unique classes in the test set\n",
    "        classes = np.unique(y_test)\n",
    "\n",
    "        # Calculate and print Accuracy, Precision, Recall\n",
    "        accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "        print(\"Accuracy:\", round(accuracy, 2))\n",
    "        print(\"Detail:\")\n",
    "        print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "        # Plot confusion matrix\n",
    "        cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "        fig, ax = plt.subplots()\n",
    "        sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, cbar=False)\n",
    "        ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes, yticklabels=classes, title=\"Confusion matrix\")\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate accuracy again (redundant, but kept for consistency)\n",
    "        accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Calculate precision, recall, and F1 score for micro and macro averages\n",
    "        precision_micro, recall_micro, f1_micro, _ = metrics.precision_recall_fscore_support(y_test, y_pred, average='micro')\n",
    "        precision_macro, recall_macro, f1_macro, _ = metrics.precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "        \n",
    "        # Return the calculated metrics\n",
    "        return accuracy, precision_micro, recall_micro, f1_micro, precision_macro, recall_macro, f1_macro"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39154fe7",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "056a1dbd",
   "metadata": {},
   "source": [
    "randomized search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704a37be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"clf\", RandomForestClassifier(random_state=0)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "parameter_grid = {\n",
    "    \"clf__n_estimators\": [10, 100, 1000],\n",
    "    'clf__max_depth': [3, 5, 10, None],\n",
    "    'clf__min_samples_split': [2, 5, 10],\n",
    "    'clf__max_samples': [0.1, 0.5, 0.8, None],\n",
    "    'clf__max_features': [1, 4, 7, 'sqrt']\n",
    "}\n",
    "\n",
    "k_fold_cv = 5 # Stratified 5-fold cross validation\n",
    "n_iter = 100\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=parameter_grid,\n",
    "    n_iter=n_iter,\n",
    "    random_state=0,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    cv=k_fold_cv,\n",
    "    scoring=scoring,\n",
    "    refit=refit \n",
    ")\n",
    "\n",
    "random_search.fit(X_train_vec, y_train)\n",
    "random_search.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "984b1215",
   "metadata": {},
   "source": [
    "fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e478ad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=random_search.best_params_[\"clf__n_estimators\"],\n",
    "                                    max_depth=random_search.best_params_[\"clf__max_depth\"],\n",
    "                                    min_samples_split=random_search.best_params_[\"clf__min_samples_split\"],\n",
    "                                    max_samples=random_search.best_params_[\"clf__max_samples\"],\n",
    "                                    max_features=random_search.best_params_[\"clf__max_features\"],\n",
    "                                    random_state=0)\n",
    "classifier.fit(X_train_vec, y_train) \n",
    "y_pred = classifier.predict(X_test_vec)\n",
    "\n",
    "accuracy_test, precision_micro_test, recall_micro_test, f1_micro_test, precision_macro_test, recall_macro_test, f1_macro_test = plot_results_topology(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5644454",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d9b34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"clf\", MultinomialNB()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "parameter_grid = {\n",
    "    'clf__alpha': [1]\n",
    "}\n",
    "\n",
    "k_fold_cv = 5 # Stratified 5-fold cross validation\n",
    "n_iter = 100\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=parameter_grid,\n",
    "    n_iter=n_iter,\n",
    "    random_state=0,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    cv=k_fold_cv,\n",
    "    scoring=scoring,\n",
    "    refit=refit\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_vec, y_train)\n",
    "random_search.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d53ac91",
   "metadata": {},
   "source": [
    "fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2674126c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_vec, y_train) \n",
    "y_pred = classifier.predict(X_test_vec)\n",
    "\n",
    "accuracy_test, precision_micro_test, recall_micro_test, f1_micro_test, precision_macro_test, recall_macro_test, f1_macro_test = plot_results_topology(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af27ba6f",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "424a7205",
   "metadata": {},
   "source": [
    "randomized search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bb9102",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"clf\", LogisticRegression(random_state=0)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "parameter_grid = {\n",
    "    'clf__penalty': [None]\n",
    "}\n",
    "\n",
    "k_fold_cv = 5 # Stratified 5-fold cross validation\n",
    "n_iter = 100\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=parameter_grid,\n",
    "    n_iter=n_iter,\n",
    "    random_state=0,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    cv=k_fold_cv,\n",
    "    scoring=scoring,\n",
    "    refit=refit\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_vec, y_train)\n",
    "random_search.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9eea6e9c",
   "metadata": {},
   "source": [
    "fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891fc650",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(random_state=0, penalty=None)\n",
    "classifier.fit(X_train_vec, y_train) \n",
    "y_pred = classifier.predict(X_test_vec)\n",
    "\n",
    "accuracy_test, precision_micro_test, recall_micro_test, f1_micro_test, precision_macro_test, recall_macro_test, f1_macro_test = plot_results_topology(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "934694e0",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98aa1b74",
   "metadata": {},
   "source": [
    "randomized search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5a6ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"clf\", SVC(random_state=0, gamma='scale')),\n",
    "    ]\n",
    ")\n",
    "\n",
    "parameter_grid = {\n",
    "    'clf__C': [1, 10, 100, 1000], \n",
    "    'clf__kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "k_fold_cv = 5 # Stratified 5-fold cross validation\n",
    "n_iter = 100\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=parameter_grid,\n",
    "    n_iter=n_iter,\n",
    "    random_state=0,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    cv=k_fold_cv,\n",
    "    scoring=scoring,\n",
    "    refit=refit \n",
    ")\n",
    "\n",
    "random_search.fit(X_train_vec, y_train)\n",
    "random_search.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b4cf8b0",
   "metadata": {},
   "source": [
    "fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ceb721",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC(random_state=0, \n",
    "                 gamma='scale',\n",
    "                 kernel=random_search.best_params_[\"clf__kernel\"],\n",
    "                 C=random_search.best_params_[\"clf__C\"],\n",
    "                 probability=True)\n",
    "classifier.fit(X_train_vec, y_train) \n",
    "y_pred = classifier.predict(X_test_vec)\n",
    "\n",
    "accuracy_test, precision_micro_test, recall_micro_test, f1_micro_test, precision_macro_test, recall_macro_test, f1_macro_test = plot_results_topology(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06ea1cdd",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42d3480c",
   "metadata": {},
   "source": [
    "randomized search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae81b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"clf\", xgb.XGBClassifier(random_state=0)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "parameter_grid = {\n",
    "    \"clf__colsample_bytree\": uniform(0.7, 0.3),\n",
    "    \"clf__gamma\": uniform(0, 0.5),\n",
    "    \"clf__learning_rate\": uniform(0.03, 0.3), # default 0.1 \n",
    "    \"clf__max_depth\": randint(2, 6), # default 3\n",
    "    \"clf__n_estimators\": randint(100, 150), # default 100\n",
    "    \"clf__subsample\": uniform(0.6, 0.4)\n",
    "}\n",
    "\n",
    "k_fold_cv = 5 # Stratified 5-fold cross validation\n",
    "n_iter = 100\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=parameter_grid,\n",
    "    n_iter=n_iter,\n",
    "    random_state=0,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    cv=k_fold_cv,\n",
    "    scoring=scoring,\n",
    "    refit=refit \n",
    ")\n",
    "\n",
    "random_search.fit(X_train_vec, y_train_encoded)\n",
    "random_search.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "132b55a1",
   "metadata": {},
   "source": [
    "fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c96728",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_encoded = le.fit_transform(y_test)\n",
    "\n",
    "classifier = xgb.XGBClassifier(random_state=0,\n",
    "                 colsample_bytree=random_search.best_params_[\"clf__colsample_bytree\"],\n",
    "                 gamma=random_search.best_params_[\"clf__gamma\"],\n",
    "                 learning_rate=random_search.best_params_[\"clf__learning_rate\"],\n",
    "                 max_depth=random_search.best_params_[\"clf__max_depth\"],\n",
    "                 n_estimators=random_search.best_params_[\"clf__n_estimators\"],\n",
    "                 subsample=random_search.best_params_[\"clf__subsample\"])\n",
    "classifier.fit(X_train_vec, y_train_encoded) \n",
    "y_pred = classifier.predict(X_test_vec)\n",
    "\n",
    "accuracy_test, precision_micro_test, recall_micro_test, f1_micro_test, precision_macro_test, recall_macro_test, f1_macro_test = plot_results_topology(y_test_encoded, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0aad1325",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "093d29d4",
   "metadata": {},
   "source": [
    "randomized search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0196fcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"clf\", KNeighborsClassifier()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "parameter_grid = {\n",
    "    'clf__n_neighbors': [1, 3, 5, 7], \n",
    "    'clf__weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "k_fold_cv = 5 # Stratified 5-fold cross validation\n",
    "n_iter = 100\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=parameter_grid,\n",
    "    n_iter=n_iter,\n",
    "    random_state=0,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    cv=k_fold_cv,\n",
    "    scoring=scoring,\n",
    "    refit=refit \n",
    ")\n",
    "\n",
    "random_search.fit(X_train_vec, y_train)\n",
    "random_search.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f736a58b",
   "metadata": {},
   "source": [
    "fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6372ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(\n",
    "                 weights=random_search.best_params_[\"clf__weights\"],\n",
    "                 n_neighbors=random_search.best_params_[\"clf__n_neighbors\"])\n",
    "classifier.fit(X_train_vec, y_train) \n",
    "y_pred = classifier.predict(X_test_vec)\n",
    "\n",
    "accuracy_test, precision_micro_test, recall_micro_test, f1_micro_test, precision_macro_test, recall_macro_test, f1_macro_test = plot_results_topology(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_cp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
