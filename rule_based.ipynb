{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9691e5-c20f-428d-aa36-1063700e3c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from Levenshtein import distance\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bece81-6220-46d3-b2e3-6e042b0d0d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "workingDir = os.path.abspath(os.path.join(''))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dea99196",
   "metadata": {},
   "source": [
    "### read df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7427ba-0458-4398-91c1-d0d7c310f48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(filepath_or_buffer=os.path.join(workingDir, 'data', 'train.csv'))\n",
    "df_test = pd.read_csv(filepath_or_buffer=os.path.join(workingDir, 'data', 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e87461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell_correction(word, corpus):\n",
    "    if word not in corpus:\n",
    "        distances = [distance(word, c) for c in corpus]\n",
    "        min_index = distances.index(min(distances))\n",
    "        corpus[min_index]\n",
    "        if len(word)/10 + 1 >=  min(distances):\n",
    "            word = corpus[min_index]\n",
    "    return word"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01348756",
   "metadata": {},
   "source": [
    "# German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75b6b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'german'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c983f0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = [word for sentence in df_train[f\"input_{language}\"] for word in sentence.split()]\n",
    "# Create a corpus as a set of unique words\n",
    "corpus = list(set(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5405cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "# Iterate over each sentence in the test dataframe\n",
    "for sen in range(0, len(df_test[f\"input_{language}\"])):\n",
    "    # Convert the sentence to a string\n",
    "    document = str(df_test[f\"input_{language}\"][sen])\n",
    "    # Split the sentence into words\n",
    "    document = document.split()\n",
    "    # Apply spell correction to each word in the sentence\n",
    "    document = [spell_correction(word, corpus) for word in document]\n",
    "    # Join the corrected words back into a single string\n",
    "    document = ' '.join(document)\n",
    "    \n",
    "    # Append the corrected sentence to the documents list\n",
    "    documents.append(document)\n",
    "\n",
    "df_test[f\"input_{language}\"] = pd.DataFrame({f\"input_{language}\": documents})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fcf3a98a",
   "metadata": {},
   "source": [
    "# Topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283170dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train[f\"input_{language}\"], df_train.Topology\n",
    "X_test, y_test = df_test[f\"input_{language}\"], df_test.Topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a33fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_cp_train = X_train[~ (y_train  == 'none')]\n",
    "doc_not_cp_train = X_train[y_train  == 'none']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0155887",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_cp_bilateral_train = X_train[y_train == 'Bilateral']\n",
    "doc_cp_not_bilateral_train = X_train[~ (y_train  == 'Bilateral') & ~ (y_train  == 'none')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb30a96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_cp_unilateral_train = X_train[y_train == 'Unilateral']\n",
    "doc_cp_not_unilateral_train = X_train[~ (y_train  == 'Unilateral') & ~ (y_train  == 'none')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e39a8d87",
   "metadata": {},
   "source": [
    "## Build rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c43f3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_dict = [['cp '], [' cp '], [' cp'], ['cerebral', 'pares'], ['cerebral', 'palsy'], ['cererbralparese'], ['zerebralpares'], ['diplegie'], ['hemiplegie'], ['hemisyndrom'],\n",
    "           ['hemipar'], ['tetra', 'pares'], ['tetraplegie'], ['cerebral', 'bewegun', 'störung'], ['zerebral', 'bewegun', 'störung']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4254c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "[doc for doc in doc_cp_train if not any([all([t in doc for t in term]) for term in cp_dict])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7174bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "[doc for doc in doc_not_cp_train if any([all([t in doc for t in term]) for term in cp_dict])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e9bceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilateral_dict = [['bilateral'], ['bein betonen spastisch'], ['diplegie'], ['diparese']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d764f992",
   "metadata": {},
   "outputs": [],
   "source": [
    "[doc for doc in doc_cp_bilateral_train if not any([all([t in doc for t in term]) for term in bilateral_dict])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646383ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "[doc for doc in doc_cp_not_bilateral_train if any([all([t in doc for t in term]) for term in bilateral_dict])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc78b0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "unilateral_dict = [['recht cp'], ['link cp'], ['cp recht'], ['cp link'], \n",
    "                   ['recht betont spastisch'], ['link betont spastisch'], \n",
    "                   ['cerebral parese recht'], ['cerebral parese link'], \n",
    "                   ['hemiparese'], ['hemiplegie'], ['hemisyndrom'], ['hemi '], ['hemipar '], ['hemisymptomatik'], ['hemispastisch'], \n",
    "                   ['zerebralparese link'], ['zerebralparese recht'],\n",
    "                   ['unilateral spastisch'], ['unilateral bein betonen spastisch'], ['unilateral cerebral'], ['unilateraler spastischer'], \n",
    "                   ['unilaterale armbetonte spastisch'], ['unilateraler spastisch'],]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91d43c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "[doc for doc in doc_cp_unilateral_train if not any([all([t in doc for t in term]) for term in unilateral_dict])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b63f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "[doc for doc in doc_cp_not_unilateral_train if any([all([t in doc for t in term]) for term in unilateral_dict])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396da464",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_pred = []\n",
    "for doc in X_train:\n",
    "    cp_pred.append(any([all([t in doc for t in term]) for term in cp_dict]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbecd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilateral_pred = []\n",
    "for doc in X_train:\n",
    "    bilateral_pred.append(any([all([t in doc for t in term]) for term in bilateral_dict]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5979117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unilateral_pred = []\n",
    "for doc in X_train:\n",
    "    unilateral_pred.append(any([all([t in doc for t in term]) for term in unilateral_dict]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0bd5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame({'cp_pred': cp_pred, \n",
    "              'bilateral_pred': bilateral_pred, \n",
    "              'unilateral_pred': unilateral_pred\n",
    "})\n",
    "\n",
    "preds['y_pred'] = 'none'\n",
    "preds.loc[preds['cp_pred'] == True, 'y_pred'] = 'Undefined'\n",
    "preds.loc[(preds['bilateral_pred'] == True) & (preds['cp_pred'] == True), 'y_pred'] = 'Bilateral'\n",
    "preds.loc[(preds['unilateral_pred'] == True) & (preds['cp_pred'] == True), 'y_pred'] = 'Unilateral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fc2d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(y_train)\n",
    "y_pred = preds.y_pred\n",
    "\n",
    "## Accuracy, Precision, Recall\n",
    "accuracy = metrics.accuracy_score(y_train, y_pred)\n",
    "print(\"Accuracy:\",  round(accuracy,2))\n",
    "print(\"Detail:\")\n",
    "print(metrics.classification_report(y_train, y_pred))\n",
    "\n",
    "## Plot confusion matrix\n",
    "cm = metrics.confusion_matrix(y_train, y_pred)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues,\n",
    "            cbar=False)\n",
    "ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes,\n",
    "       yticklabels=classes, title=\"Confusion matrix\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "accuracy_train = metrics.accuracy_score(y_train, y_pred)\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision_micro_train, recall_micro_train, f1_micro_train, _ = metrics.precision_recall_fscore_support(y_train, y_pred, average='micro')\n",
    "precision_macro_train, recall_macro_train, f1_macro_train, _ = metrics.precision_recall_fscore_support(y_train, y_pred, average='macro')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8429f552",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e87ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_pred = []\n",
    "for doc in X_test:\n",
    "    cp_pred.append(any([all([t in doc for t in term]) for term in cp_dict]))\n",
    "bilateral_pred = []\n",
    "for doc in X_test:\n",
    "    bilateral_pred.append(any([all([t in doc for t in term]) for term in bilateral_dict]))\n",
    "unilateral_pred = []\n",
    "for doc in X_test:\n",
    "    unilateral_pred.append(any([all([t in doc for t in term]) for term in unilateral_dict]))\n",
    "preds = pd.DataFrame({'cp_pred': cp_pred, \n",
    "              'bilateral_pred': bilateral_pred, \n",
    "              'unilateral_pred': unilateral_pred\n",
    "})\n",
    "\n",
    "preds['y_pred'] = 'none'\n",
    "preds.loc[preds['cp_pred'] == True, 'y_pred'] = 'Undefined'\n",
    "preds.loc[(preds['bilateral_pred'] == True) & (preds['cp_pred'] == True), 'y_pred'] = 'Bilateral'\n",
    "preds.loc[(preds['unilateral_pred'] == True) & (preds['cp_pred'] == True), 'y_pred'] = 'Unilateral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42d58e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(y_test)\n",
    "y_pred = preds.y_pred\n",
    "\n",
    "## Accuracy, Precision, Recall\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\",  round(accuracy,2))\n",
    "print(\"Detail:\")\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "## Plot confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues,\n",
    "            cbar=False)\n",
    "ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes,\n",
    "       yticklabels=classes, title=\"Confusion matrix\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "accuracy_test = metrics.accuracy_score(y_test, y_pred)\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision_micro_test, recall_micro_test, f1_micro_test, _ = metrics.precision_recall_fscore_support(y_test, y_pred, average='micro')\n",
    "precision_macro_test, recall_macro_test, f1_macro_test, _ = metrics.precision_recall_fscore_support(y_test, y_pred, average='macro')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25279366",
   "metadata": {},
   "source": [
    "# English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102815fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b921e72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = [word for sentence in df_train[f\"input_{language}\"] for word in sentence.split()]\n",
    "# Create a corpus as a set of unique words\n",
    "corpus = list(set(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205694e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for sen in range(0, len(df_test[f\"input_{language}\"])):\n",
    "    document = str(df_test[f\"input_{language}\"][sen])\n",
    "    document = document.split()\n",
    "    document = [spell_correction(word, corpus) for word in document]\n",
    "    document = ' '.join(document)\n",
    "    \n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca0a2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[f\"input_{language}\"] = pd.DataFrame({f\"input_{language}\": documents})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cbab924f",
   "metadata": {},
   "source": [
    "# Topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c707c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train[f\"input_{language}\"], df_train.Topology\n",
    "X_test, y_test = df_test[f\"input_{language}\"], df_test.Topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58a2869",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_cp_train = X_train[~ (y_train  == 'none')]\n",
    "doc_not_cp_train = X_train[y_train  == 'none']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b283f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_cp_bilateral_train = X_train[y_train == 'Bilateral']\n",
    "doc_cp_not_bilateral_train = X_train[~ (y_train  == 'Bilateral') & ~ (y_train  == 'none')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a28265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_cp_unilateral_train = X_train[y_train == 'Unilateral']\n",
    "doc_cp_not_unilateral_train = X_train[~ (y_train  == 'Unilateral') & ~ (y_train  == 'none')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e46d686",
   "metadata": {},
   "source": [
    "## Build rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664d5e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_dict = [['cp '], [' cp '], [' cp'], ['cerebral', 'pares'], ['cerebral', 'palsy'], ['hemiparesis'], ['hemiplegia'], ['hemiparous'], \n",
    "           ['hemisyndrome'], ['tetraparesis'], ['tetraplegia'], ['diplegia'], ['cerebral', 'movement', 'disorder']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9a1e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "[doc for doc in doc_cp_train if not any([all([t in doc for t in term]) for term in cp_dict])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e3be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "[doc for doc in doc_not_cp_train if any([all([t in doc for t in term]) for term in cp_dict])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93582a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilateral_dict = [['bilateral'], ['diplegia'], ['diparesis'], ['leg stressed spastic'], ['arm stressed spastic'], ['leg stressed cerebral'], ['arm stressed cerebral']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58712848",
   "metadata": {},
   "outputs": [],
   "source": [
    "[doc for doc in doc_cp_bilateral_train if not any([all([t in doc for t in term]) for term in bilateral_dict])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61862609",
   "metadata": {},
   "outputs": [],
   "source": [
    "[doc for doc in doc_cp_not_bilateral_train if any([all([t in doc for t in term]) for term in bilateral_dict])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778cce5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unilateral_dict = [['right cerebral'], ['left cerebral'], ['right cp'], ['left cp'], ['cp on the right'], ['cp on the left'], ['right sided spastic'], ['left sided spastic'],\n",
    "                   ['cerebral palsy right'], ['cerebral palsy left'], \n",
    "                   ['hemiparesis'], ['hemiplegia'], ['hemi '], ['hemiplegic'], ['hemisyndrome'], ['hemiparous'], ['hemispastic'], ['hemisymptomatic'],\n",
    "                   ['unilateral', 'spastic'], ['unilateral', 'cp'], ['unilateral cerebral'], ['unilateral arm stressed spastic'], ['unilateral leg stressed spastic'],\n",
    "                   ['right hand cerebral'], ['left hand cerebral']\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a130fb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "[doc for doc in doc_cp_unilateral_train if not any([all([t in doc for t in term]) for term in unilateral_dict])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b589b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "[doc for doc in doc_cp_not_unilateral_train if any([all([t in doc for t in term]) for term in unilateral_dict])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30114b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_pred = []\n",
    "for doc in X_train:\n",
    "    cp_pred.append(any([all([t in doc for t in term]) for term in cp_dict]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e88cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilateral_pred = []\n",
    "for doc in X_train:\n",
    "    bilateral_pred.append(any([all([t in doc for t in term]) for term in bilateral_dict]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71bd383",
   "metadata": {},
   "outputs": [],
   "source": [
    "unilateral_pred = []\n",
    "for doc in X_train:\n",
    "    unilateral_pred.append(any([all([t in doc for t in term]) for term in unilateral_dict]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f829f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame({'cp_pred': cp_pred, \n",
    "              'bilateral_pred': bilateral_pred, \n",
    "              'unilateral_pred': unilateral_pred\n",
    "})\n",
    "\n",
    "preds['y_pred'] = 'none'\n",
    "preds.loc[preds['cp_pred'] == True, 'y_pred'] = 'Undefined'\n",
    "preds.loc[(preds['bilateral_pred'] == True) & (preds['cp_pred'] == True), 'y_pred'] = 'Bilateral'\n",
    "preds.loc[(preds['unilateral_pred'] == True) & (preds['cp_pred'] == True), 'y_pred'] = 'Unilateral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b1f6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(y_train)\n",
    "y_pred = preds.y_pred\n",
    "\n",
    "## Accuracy, Precision, Recall\n",
    "accuracy = metrics.accuracy_score(y_train, y_pred)\n",
    "print(\"Accuracy:\",  round(accuracy,2))\n",
    "print(\"Detail:\")\n",
    "print(metrics.classification_report(y_train, y_pred))\n",
    "\n",
    "## Plot confusion matrix\n",
    "cm = metrics.confusion_matrix(y_train, y_pred)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues,\n",
    "            cbar=False)\n",
    "ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes,\n",
    "       yticklabels=classes, title=\"Confusion matrix\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "accuracy_train = metrics.accuracy_score(y_train, y_pred)\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision_micro_train, recall_micro_train, f1_micro_train, _ = metrics.precision_recall_fscore_support(y_train, y_pred, average='micro')\n",
    "precision_macro_train, recall_macro_train, f1_macro_train, _ = metrics.precision_recall_fscore_support(y_train, y_pred, average='macro')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "46839785",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f67aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_pred = []\n",
    "for doc in X_test:\n",
    "    cp_pred.append(any([all([t in doc for t in term]) for term in cp_dict]))\n",
    "bilateral_pred = []\n",
    "for doc in X_test:\n",
    "    bilateral_pred.append(any([all([t in doc for t in term]) for term in bilateral_dict]))\n",
    "unilateral_pred = []\n",
    "for doc in X_test:\n",
    "    unilateral_pred.append(any([all([t in doc for t in term]) for term in unilateral_dict]))\n",
    "preds = pd.DataFrame({'cp_pred': cp_pred, \n",
    "              'bilateral_pred': bilateral_pred, \n",
    "              'unilateral_pred': unilateral_pred\n",
    "})\n",
    "\n",
    "preds['y_pred'] = 'none'\n",
    "preds.loc[preds['cp_pred'] == True, 'y_pred'] = 'Undefined'\n",
    "preds.loc[(preds['bilateral_pred'] == True) & (preds['cp_pred'] == True), 'y_pred'] = 'Bilateral'\n",
    "preds.loc[(preds['unilateral_pred'] == True) & (preds['cp_pred'] == True), 'y_pred'] = 'Unilateral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfd2506",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(y_test)\n",
    "y_pred = preds.y_pred\n",
    "\n",
    "## Accuracy, Precision, Recall\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\",  round(accuracy,2))\n",
    "print(\"Detail:\")\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "## Plot confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues,\n",
    "            cbar=False)\n",
    "ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes,\n",
    "       yticklabels=classes, title=\"Confusion matrix\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "accuracy_test = metrics.accuracy_score(y_test, y_pred)\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision_micro_test, recall_micro_test, f1_micro_test, _ = metrics.precision_recall_fscore_support(y_test, y_pred, average='micro')\n",
    "precision_macro_test, recall_macro_test, f1_macro_test, _ = metrics.precision_recall_fscore_support(y_test, y_pred, average='macro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_cp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
